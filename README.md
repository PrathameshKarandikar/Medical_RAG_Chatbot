# ğŸ¥ Medical RAG Chatbot

This project implements a **Retrieval-Augmented Generation (RAG) Chatbot** for answering medical-related queries.  
It combines **LangChain**, **HuggingFace Embeddings**, **ChromaDB**, and a **HuggingFace Chat Model** to provide accurate, context-aware answers.  
A **Gradio** interface is used for easy interaction.  

---

## ğŸš€ Features
- âœ… Retrieval-Augmented Generation (RAG) pipeline for contextual answers  
- âœ… Uses **HuggingFace Sentence Transformers** for embeddings  
- âœ… Stores and retrieves knowledge from **ChromaDB**  
- âœ… HuggingFace Chat Model for natural responses  
- âœ… **Gradio Demo UI** for user interaction  

---

## ğŸ› ï¸ Tech Stack
- **LangChain** â€“ RAG orchestration  
- **HuggingFace Sentence Transformers** â€“ Embeddings (`all-MiniLM-L6-v2`)  
- **ChromaDB** â€“ Vector database for storage and retrieval  
- **HuggingFace Chat Model** â€“ LLM for generating responses  
- **Gradio** â€“ Web-based demo interface  

---

## ğŸ“‚ Project Structure

medical-rag-chatbot/

â”‚â”€â”€ data/

â”‚ â””â”€â”€ medical_qna.csv # Medical Q&A dataset

â”‚â”€â”€ medical_RAG_chatbot.ipynb # Main Notebook with RAG pipeline + Gradio demo

â”‚â”€â”€ README.md # Project documentation

## ğŸ”§ How It Works

1. Load Dataset â†’ Import medical Q&A data.

2. Embed Documents â†’ Convert text into embeddings using HuggingFace Sentence Transformer.

3. Store in ChromaDB â†’ Save embeddings in a vector database.

4. RAG Pipeline â†’ Retrieve relevant chunks and generate answers using HuggingFace Chat Model.

5. Gradio UI â†’ User inputs query, chatbot returns contextual answer.
